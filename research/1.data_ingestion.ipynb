{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9177ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c392a61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\akato\\\\Desktop\\\\MLOps\\\\datascienceproject_fullflow\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d618ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\akato\\\\Desktop\\\\MLOps\\\\datascienceproject_fullflow'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294073ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code transfered to src entity.config.configuration.py\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feded8de",
   "metadata": {},
   "source": [
    "# Configuration Update\n",
    "We're transitioning from ZIP file handling to direct CSV handling. This requires updates to:\n",
    "1. DataIngestionConfig class structure\n",
    "2. Configuration file (config.yaml)\n",
    "3. Data ingestion implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import constants and utility functions from the project\n",
    "# Code transfered to src.datascienceproject.config.configuration.py\n",
    "from src.datascienceproject.constant import *  # Import all constants\n",
    "from src.datascienceproject.utils.common import read_yaml, create_directories  # Import specific utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f3a51a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath=CONFIG_FILE_PATH,\n",
    "                 params_filepath=PARAMS_FILE_PATH,\n",
    "                 schema_filepath=SCHEMA_FILE_PATH):\n",
    "        # Convert paths to strings for read_yaml\n",
    "        self.config = read_yaml(str(config_filepath))\n",
    "        self.params = read_yaml(str(params_filepath))\n",
    "        self.schema = read_yaml(str(schema_filepath))\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_file=config.local_data_file,\n",
    "            unzip_dir=config.unzip_dir\n",
    "        )\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfered to src.components.data_ingestion.py \n",
    "import os\n",
    "import urllib.request as request\n",
    "from src.datascienceproject import logger\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "33528a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def verify_zip_file(self, file_path: str) -> bool:\n",
    "        \"\"\"\n",
    "        Verify if the file is a valid ZIP file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                # Check ZIP file signature (PK\\x03\\x04)\n",
    "                is_zip = f.read(4).startswith(b'PK\\x03\\x04')\n",
    "                if not is_zip:\n",
    "                    logger.error(f\"File {file_path} does not have a valid ZIP signature\")\n",
    "                return is_zip\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error verifying ZIP file: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def download_file(self):\n",
    "        \"\"\"\n",
    "        Downloads file from source URL if it doesn't exist locally\n",
    "        \"\"\"\n",
    "        try:\n",
    "            file_path = str(self.config.local_data_file)\n",
    "            if not os.path.exists(file_path):\n",
    "                # Create directory if it doesn't exist\n",
    "                os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "                \n",
    "                logger.info(f\"Downloading from {self.config.source_URL} to {file_path}\")\n",
    "                filename, headers = request.urlretrieve(\n",
    "                    url=self.config.source_URL,\n",
    "                    filename=file_path\n",
    "                )\n",
    "                logger.info(f\"File downloaded successfully to: {filename}\")\n",
    "                logger.debug(f\"Download headers: {headers}\")\n",
    "            \n",
    "            # Verify the file whether it was just downloaded or existed before\n",
    "            if not self.verify_zip_file(file_path):\n",
    "                # If file exists but is invalid, try to download again\n",
    "                logger.warning(\"Invalid ZIP file detected, attempting to download again...\")\n",
    "                if os.path.exists(file_path):\n",
    "                    os.remove(file_path)\n",
    "                filename, headers = request.urlretrieve(\n",
    "                    url=self.config.source_URL,\n",
    "                    filename=file_path\n",
    "                )\n",
    "                if not self.verify_zip_file(file_path):\n",
    "                    raise Exception(\"Failed to download a valid ZIP file\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error downloading file: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        Extracts the zip file into the specified directory\n",
    "        \"\"\"\n",
    "        try:\n",
    "            file_path = str(self.config.local_data_file)\n",
    "            unzip_path = str(self.config.unzip_dir)\n",
    "            \n",
    "            # Verify zip file before attempting to extract\n",
    "            if not self.verify_zip_file(file_path):\n",
    "                raise Exception(\"Cannot extract: Invalid ZIP file\")\n",
    "            \n",
    "            os.makedirs(unzip_path, exist_ok=True)\n",
    "            \n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                # List contents before extracting\n",
    "                logger.info(f\"ZIP file contains: {zip_ref.namelist()}\")\n",
    "                zip_ref.extractall(unzip_path)\n",
    "            logger.info(f\"File extracted successfully to: {unzip_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting file: {str(e)}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a57bdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 07:24:33,375] INFO in 2571272890: Starting data ingestion process...\n",
      "[2025-08-24 07:24:33,376] INFO in common: YAML file configs\\config.yaml loaded successfully.\n",
      "[2025-08-24 07:24:33,376] INFO in common: YAML file configs\\config.yaml loaded successfully.\n",
      "[2025-08-24 07:24:33,382] INFO in common: YAML file params.yaml loaded successfully.\n",
      "[2025-08-24 07:24:33,387] INFO in common: YAML file schema.yaml loaded successfully.\n",
      "[2025-08-24 07:24:33,390] INFO in common: created directory at: artifacts\n",
      "[2025-08-24 07:24:33,391] INFO in common: created directory at: artifacts/data_ingestion\n",
      "[2025-08-24 07:24:33,382] INFO in common: YAML file params.yaml loaded successfully.\n",
      "[2025-08-24 07:24:33,387] INFO in common: YAML file schema.yaml loaded successfully.\n",
      "[2025-08-24 07:24:33,390] INFO in common: created directory at: artifacts\n",
      "[2025-08-24 07:24:33,391] INFO in common: created directory at: artifacts/data_ingestion\n",
      "[2025-08-24 07:24:33,394] INFO in 2571272890: Downloading file...\n",
      "[2025-08-24 07:24:33,397] ERROR in 3506057583: File artifacts/data_ingestion/data.zip does not have a valid ZIP signature\n",
      "[2025-08-24 07:24:33,399] WARNING in 3506057583: Invalid ZIP file detected, attempting to download again...\n",
      "[2025-08-24 07:24:33,394] INFO in 2571272890: Downloading file...\n",
      "[2025-08-24 07:24:33,397] ERROR in 3506057583: File artifacts/data_ingestion/data.zip does not have a valid ZIP signature\n",
      "[2025-08-24 07:24:33,399] WARNING in 3506057583: Invalid ZIP file detected, attempting to download again...\n",
      "[2025-08-24 07:24:33,731] INFO in 2571272890: Extracting file...\n",
      "[2025-08-24 07:24:33,731] INFO in 2571272890: Extracting file...\n",
      "[2025-08-24 07:24:33,789] INFO in 3506057583: ZIP file contains: ['winequality-white.csv']\n",
      "[2025-08-24 07:24:33,794] INFO in 3506057583: File extracted successfully to: artifacts/data_ingestion\n",
      "[2025-08-24 07:24:33,794] INFO in 2571272890: Data ingestion completed successfully!\n",
      "[2025-08-24 07:24:33,789] INFO in 3506057583: ZIP file contains: ['winequality-white.csv']\n",
      "[2025-08-24 07:24:33,794] INFO in 3506057583: File extracted successfully to: artifacts/data_ingestion\n",
      "[2025-08-24 07:24:33,794] INFO in 2571272890: Data ingestion completed successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logger.info(\"Starting data ingestion process...\")\n",
    "    \n",
    "    # Initialize configuration\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    \n",
    "    # Create data ingestion object\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    \n",
    "    # Download and extract file\n",
    "    logger.info(\"Downloading file...\")\n",
    "    data_ingestion.download_file()\n",
    "    \n",
    "    logger.info(\"Extracting file...\")\n",
    "    data_ingestion.extract_zip_file()\n",
    "    \n",
    "    logger.info(\"Data ingestion completed successfully!\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in data ingestion process: {str(e)}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4467bdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-24 07:20:18,772] INFO in common: YAML file configs\\config.yaml loaded successfully.\n",
      "[2025-08-24 07:20:18,778] INFO in common: YAML file params.yaml loaded successfully.\n",
      "[2025-08-24 07:20:18,780] INFO in common: YAML file schema.yaml loaded successfully.\n",
      "[2025-08-24 07:20:18,782] INFO in common: created directory at: artifacts\n",
      "[2025-08-24 07:20:18,785] INFO in common: created directory at: artifacts/data_ingestion\n",
      "Configuration values:\n",
      "Source URL: https://github.com/Dadaranger/dataset/blob/main/winequality-white.zip\n",
      "Local file: artifacts/data_ingestion/data.zip\n",
      "Unzip dir: artifacts/data_ingestion\n",
      "\n",
      "URL Status: 200\n",
      "URL Headers:\n",
      "Date: Sat, 23 Aug 2025 23:20:19 GMT\n",
      "Content-Type: text/html; charset=utf-8\n",
      "Vary: X-PJAX, X-PJAX-Container, Turbo-Visit, Turbo-Frame, X-Requested-With,Accept-Encoding, Accept, X-Requested-With\n",
      "x-repository-download: git clone https://github.com/Dadaranger/dataset.git\n",
      "x-raw-download: https://raw.githubusercontent.com/Dadaranger/dataset/main/winequality-white.zip\n",
      "ETag: W/\"84b626d10c4658e1425a8659a8db2e98\"\n",
      "Cache-Control: max-age=0, private, must-revalidate\n",
      "Strict-Transport-Security: max-age=31536000; includeSubdomains; preload\n",
      "X-Frame-Options: deny\n",
      "X-Content-Type-Options: nosniff\n",
      "X-XSS-Protection: 0\n",
      "Referrer-Policy: no-referrer-when-downgrade\n",
      "Content-Security-Policy: default-src 'none'; base-uri 'self'; child-src github.githubassets.com github.com/assets-cdn/worker/ github.com/assets/ gist.github.com/assets-cdn/worker/; connect-src 'self' uploads.github.com www.githubstatus.com collector.github.com raw.githubusercontent.com api.github.com github-cloud.s3.amazonaws.com github-production-repository-file-5c1aeb.s3.amazonaws.com github-production-upload-manifest-file-7fdce7.s3.amazonaws.com github-production-user-asset-6210df.s3.amazonaws.com *.rel.tunnels.api.visualstudio.com wss://*.rel.tunnels.api.visualstudio.com objects-origin.githubusercontent.com copilot-proxy.githubusercontent.com proxy.individual.githubcopilot.com proxy.business.githubcopilot.com proxy.enterprise.githubcopilot.com *.actions.githubusercontent.com wss://*.actions.githubusercontent.com productionresultssa0.blob.core.windows.net/ productionresultssa1.blob.core.windows.net/ productionresultssa2.blob.core.windows.net/ productionresultssa3.blob.core.windows.net/ productionresultssa4.blob.core.windows.net/ productionresultssa5.blob.core.windows.net/ productionresultssa6.blob.core.windows.net/ productionresultssa7.blob.core.windows.net/ productionresultssa8.blob.core.windows.net/ productionresultssa9.blob.core.windows.net/ productionresultssa10.blob.core.windows.net/ productionresultssa11.blob.core.windows.net/ productionresultssa12.blob.core.windows.net/ productionresultssa13.blob.core.windows.net/ productionresultssa14.blob.core.windows.net/ productionresultssa15.blob.core.windows.net/ productionresultssa16.blob.core.windows.net/ productionresultssa17.blob.core.windows.net/ productionresultssa18.blob.core.windows.net/ productionresultssa19.blob.core.windows.net/ github-production-repository-image-32fea6.s3.amazonaws.com github-production-release-asset-2e65be.s3.amazonaws.com insights.github.com wss://alive.github.com wss://alive-staging.github.com api.githubcopilot.com api.individual.githubcopilot.com api.business.githubcopilot.com api.enterprise.githubcopilot.com; font-src github.githubassets.com; form-action 'self' github.com gist.github.com copilot-workspace.githubnext.com objects-origin.githubusercontent.com; frame-ancestors 'none'; frame-src viewscreen.githubusercontent.com notebooks.githubusercontent.com; img-src 'self' data: blob: github.githubassets.com media.githubusercontent.com camo.githubusercontent.com identicons.github.com avatars.githubusercontent.com private-avatars.githubusercontent.com github-cloud.s3.amazonaws.com objects.githubusercontent.com release-assets.githubusercontent.com secured-user-images.githubusercontent.com/ user-images.githubusercontent.com/ private-user-images.githubusercontent.com opengraph.githubassets.com copilotprodattachments.blob.core.windows.net/github-production-copilot-attachments/ github-production-user-asset-6210df.s3.amazonaws.com customer-stories-feed.github.com spotlights-feed.github.com objects-origin.githubusercontent.com *.githubusercontent.com; manifest-src 'self'; media-src github.com user-images.githubusercontent.com/ secured-user-images.githubusercontent.com/ private-user-images.githubusercontent.com github-production-user-asset-6210df.s3.amazonaws.com gist.github.com; script-src github.githubassets.com; style-src 'unsafe-inline' github.githubassets.com; upgrade-insecure-requests; worker-src github.githubassets.com github.com/assets-cdn/worker/ github.com/assets/ gist.github.com/assets-cdn/worker/\n",
      "Server: github.com\n",
      "Content-Encoding: gzip\n",
      "Accept-Ranges: bytes\n",
      "Set-Cookie: _gh_sess=W%2BTVarkPnGa41tagxgl3ExqKGGxQ4kBkG7UBV6m%2FpK2dJ0GsYqS4V8gCDrTIQanOvx3M%2FEwC3lIoqp5JQ3XMBcDhxnFRuDHwL0XeqKnUAQWYDGy711acYOxyuNrlz7iXJxMwoqmveuWPwVpbcuL3%2BovZxV2zZMyHB%2FrkMN15gdrb1iffiPUCrTWZyHpPvRZ3r4qLxFiZKfw%2FseZEHEIKTG2BfL2UU%2BV1Jn5UgS%2FCrs1SOUbjxE75tTVyav%2BJRqtNbkis9xSCWhLgy1zlNRczNQ%3D%3D--csntLv7LYDcIKEIv--BycArq%2BP77qt8IJ%2BUTP06g%3D%3D; Path=/; HttpOnly; Secure; SameSite=Lax, _octo=GH1.1.2090782608.1755991219; Path=/; Domain=github.com; Expires=Sun, 23 Aug 2026 23:20:19 GMT; Secure; SameSite=Lax, logged_in=no; Path=/; Domain=github.com; Expires=Sun, 23 Aug 2026 23:20:19 GMT; HttpOnly; Secure; SameSite=Lax\n",
      "X-GitHub-Request-Id: 3C7B:243324:1DF04A1:266D9BB:68AA4CB3\n"
     ]
    }
   ],
   "source": [
    "# Inspect configuration\n",
    "config = ConfigurationManager()\n",
    "data_ingestion_config = config.get_data_ingestion_config()\n",
    "print(\"Configuration values:\")\n",
    "print(f\"Source URL: {data_ingestion_config.source_URL}\")\n",
    "print(f\"Local file: {data_ingestion_config.local_data_file}\")\n",
    "print(f\"Unzip dir: {data_ingestion_config.unzip_dir}\")\n",
    "\n",
    "# Verify URL is accessible\n",
    "import requests\n",
    "try:\n",
    "    response = requests.head(data_ingestion_config.source_URL)\n",
    "    print(f\"\\nURL Status: {response.status_code}\")\n",
    "    print(\"URL Headers:\")\n",
    "    for key, value in response.headers.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking URL: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41c0d69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Headers:\n",
      "Connection: keep-alive\n",
      "Content-Length: 73146\n",
      "Cache-Control: max-age=300\n",
      "Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'; sandbox\n",
      "Content-Type: application/zip\n",
      "ETag: W/\"6185468f1650cf78b9373e579b5619e55f60ad823ad68fa1ea3c31715584fdda\"\n",
      "Strict-Transport-Security: max-age=31536000\n",
      "X-Content-Type-Options: nosniff\n",
      "X-Frame-Options: deny\n",
      "X-XSS-Protection: 1; mode=block\n",
      "X-GitHub-Request-Id: 91B4:37C012:72F25:97C26:68AA4D00\n",
      "Accept-Ranges: bytes\n",
      "Date: Sat, 23 Aug 2025 23:23:17 GMT\n",
      "Via: 1.1 varnish\n",
      "X-Served-By: cache-pdk-kfty8610086-PDK\n",
      "X-Cache: HIT\n",
      "X-Cache-Hits: 0\n",
      "X-Timer: S1755991398.882521,VS0,VE2\n",
      "Vary: Authorization,Accept-Encoding\n",
      "Access-Control-Allow-Origin: *\n",
      "Cross-Origin-Resource-Policy: cross-origin\n",
      "X-Fastly-Request-ID: 17315cd26f1013b57736b7ca0c9fdcff2e46ffa5\n",
      "Expires: Sat, 23 Aug 2025 23:28:17 GMT\n",
      "Source-Age: 101\n",
      "\n",
      "File header: 504b0304\n",
      "Is valid ZIP: True\n"
     ]
    }
   ],
   "source": [
    "# Test raw GitHub URL\n",
    "import requests\n",
    "import os\n",
    "\n",
    "raw_url = \"https://raw.githubusercontent.com/Dadaranger/dataset/main/winequality-white.zip\"\n",
    "test_file = \"test_download.zip\"\n",
    "\n",
    "try:\n",
    "    # Download with requests to see response details\n",
    "    response = requests.get(raw_url)\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(\"Headers:\")\n",
    "    for key, value in response.headers.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Save the content\n",
    "        with open(test_file, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        # Check file signature\n",
    "        with open(test_file, \"rb\") as f:\n",
    "            header = f.read(4).hex()\n",
    "            print(f\"\\nFile header: {header}\")\n",
    "            is_zip = header.startswith('504b0304')\n",
    "            print(f\"Is valid ZIP: {is_zip}\")\n",
    "        \n",
    "        # Clean up\n",
    "        os.remove(test_file)\n",
    "    else:\n",
    "        print(f\"\\nFailed to download. Status code: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    if os.path.exists(test_file):\n",
    "        os.remove(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc8bdd2",
   "metadata": {},
   "source": [
    "# GitHub URL Format\n",
    "When downloading files from GitHub:\n",
    "- ❌ Don't use: `https://github.com/user/repo/blob/branch/file`\n",
    "- ✅ Use: `https://raw.githubusercontent.com/user/repo/branch/file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223292b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display current config file contents\n",
    "import yaml\n",
    "\n",
    "config_path = \"configs/config.yaml\"\n",
    "print(\"Current config.yaml contents:\")\n",
    "print(\"-\" * 50)\n",
    "with open(config_path, 'r') as f:\n",
    "    print(yaml.safe_dump(yaml.safe_load(f), default_flow_style=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb8fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update config with correct URL\n",
    "config_path = \"configs/config.yaml\"\n",
    "\n",
    "# Read current config\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Update the URL\n",
    "config['data_ingestion']['source_URL'] = \"https://raw.githubusercontent.com/Dadaranger/dataset/main/winequality-white.zip\"\n",
    "\n",
    "# Save updated config\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.safe_dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(\"Config updated successfully!\")\n",
    "print(\"\\nNew config.yaml contents:\")\n",
    "print(\"-\" * 50)\n",
    "print(yaml.safe_dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226019c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up old files\n",
    "import shutil\n",
    "\n",
    "zip_path = \"artifacts/data_ingestion/data.zip\"\n",
    "unzip_dir = \"artifacts/data_ingestion\"\n",
    "\n",
    "# Remove old files\n",
    "if os.path.exists(zip_path):\n",
    "    os.remove(zip_path)\n",
    "    print(f\"Removed old zip file: {zip_path}\")\n",
    "\n",
    "# Clear the unzip directory but keep the directory itself\n",
    "if os.path.exists(unzip_dir):\n",
    "    for item in os.listdir(unzip_dir):\n",
    "        item_path = os.path.join(unzip_dir, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)\n",
    "    print(f\"Cleared contents of: {unzip_dir}\")\n",
    "\n",
    "print(\"Ready to try data ingestion again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e37555aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists and its size is: 182952 bytes\n",
      "File header (first 4 bytes): 0a0a0a0a\n",
      "Is valid ZIP header: False\n"
     ]
    }
   ],
   "source": [
    "# Debugging cell\n",
    "import os\n",
    "\n",
    "# Check file existence and size\n",
    "zip_path = \"artifacts/data_ingestion/data.zip\"\n",
    "if os.path.exists(zip_path):\n",
    "    file_size = os.path.getsize(zip_path)\n",
    "    print(f\"File exists and its size is: {file_size} bytes\")\n",
    "    \n",
    "    # Read first few bytes to check file signature\n",
    "    with open(zip_path, 'rb') as f:\n",
    "        header = f.read(4).hex()\n",
    "        print(f\"File header (first 4 bytes): {header}\")\n",
    "        # ZIP file should start with PK\\x03\\x04 (hex: 504b0304)\n",
    "        is_zip = header.startswith('504b0304')\n",
    "        print(f\"Is valid ZIP header: {is_zip}\")\n",
    "else:\n",
    "    print(\"File does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e164cbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
